# Explainable Artificial Intelligence Notebooks

This page is a collection of Jupyter Notebooks about Explainable Artificial Intelligence (XAI) - focusing on how to use certain techniques using Python. It aims at Data Scientists and Python programmers who want to dive into the topic.

Contributions and feedback are very welcome! In case you see room for improvement, please [create a github issue](https://github.com/haesleinhuepf/xai/issues) and/or consider [contributing](https://github.com/haesleinhuepf/xai/blob/main/CONTRIBUTING.md).

## Topics

The notebook collection currently covers these topics:
* SHapley Additive Explanations (SHAP)
* Gradient-based Class Activation Maps (Grad-CAM)

## Covered Python libraries and software

In these notebooks we use non-standard libraries from the AI / XAI field. 

* [torchvision](https://pytorch.org/vision/stable/index.html)
* [shap](https://shap.readthedocs.io/en/latest/)

## Acknowledgements

We acknowledge the financial support by the Federal Ministry of Education and Research of Germany and by Sächsische Staatsministerium für Wissenschaft, Kultur und Tourismus in the programme Center of Excellence for AI-research „Center for Scalable Data Analytics and Artificial Intelligence Dresden/Leipzig“, project identification number: ScaDS.AI